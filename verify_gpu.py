#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPU, CUDA å’Œ cuDNN éªŒè¯è„šæœ¬
æ£€æŸ¥ TensorFlow å’Œ PyTorch çš„ GPU æ”¯æŒæƒ…å†µ
"""

import sys
import os

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    if sys.stdout.encoding != 'utf-8':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


def verify_tensorflow_gpu():
    """éªŒè¯ TensorFlow GPU é…ç½®"""
    print("=" * 60)
    print("æ£€æŸ¥ TensorFlow GPU æ”¯æŒ")
    print("=" * 60)
    
    try:
        import tensorflow as tf
        print(f"âœ… TensorFlow ç‰ˆæœ¬: {tf.__version__}")
        
        # æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
        gpus = tf.config.list_physical_devices('GPU')
        print(f"\n{'âœ…' if len(gpus) > 0 else 'âŒ'} GPU å¯ç”¨: {len(gpus) > 0}")
        
        if gpus:
            print(f"   æ£€æµ‹åˆ° {len(gpus)} å— GPU:")
            for i, gpu in enumerate(gpus):
                print(f"   - GPU {i}: {gpu.name}")
            
            # æ‰“å° CUDA å’Œ cuDNN ç‰ˆæœ¬
            build_info = tf.sysconfig.get_build_info()
            cuda_version = build_info.get('cuda_version', 'N/A')
            cudnn_version = build_info.get('cudnn_version', 'N/A')
            
            print(f"\n   CUDA ç‰ˆæœ¬: {cuda_version}")
            print(f"   cuDNN ç‰ˆæœ¬: {cudnn_version}")
            
            # æµ‹è¯•ç®€å•æ“ä½œ
            try:
                with tf.device('/GPU:0'):
                    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
                    c = tf.matmul(a, b)
                print(f"\n   âœ… GPU è®¡ç®—æµ‹è¯•æˆåŠŸ")
            except Exception as e:
                print(f"\n   âŒ GPU è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        else:
            print("   æœªæ£€æµ‹åˆ° GPU,ä½¿ç”¨ CPU æ¨¡å¼")
            
    except ImportError:
        print("âŒ TensorFlow æœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ TensorFlow æ—¶å‡ºé”™: {e}")
        return False
    
    return len(gpus) > 0 if gpus else False


def verify_pytorch_gpu():
    """éªŒè¯ PyTorch GPU é…ç½®"""
    print("\n" + "=" * 60)
    print("æ£€æŸ¥ PyTorch GPU æ”¯æŒ")
    print("=" * 60)
    
    try:
        import torch
        print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
        cuda_available = torch.cuda.is_available()
        print(f"\n{'âœ…' if cuda_available else 'âŒ'} GPU å¯ç”¨: {cuda_available}")
        
        if cuda_available:
            device_count = torch.cuda.device_count()
            print(f"   æ£€æµ‹åˆ° {device_count} å— GPU:")
            
            for i in range(device_count):
                print(f"   - GPU {i}: {torch.cuda.get_device_name(i)}")
                
            # æ‰“å° CUDA ç‰ˆæœ¬
            cuda_version = torch.version.cuda
            print(f"\n   CUDA ç‰ˆæœ¬: {cuda_version}")
            
            # æ‰“å° cuDNN ç‰ˆæœ¬
            if torch.backends.cudnn.enabled:
                cudnn_version = torch.backends.cudnn.version()
                print(f"   cuDNN ç‰ˆæœ¬: {cudnn_version}")
                print(f"   cuDNN å·²å¯ç”¨: {torch.backends.cudnn.enabled}")
            else:
                print(f"   cuDNN æœªå¯ç”¨")
            
            # æµ‹è¯•ç®€å•æ“ä½œ
            try:
                x = torch.rand(3, 3).cuda()
                y = torch.rand(3, 3).cuda()
                z = torch.matmul(x, y)
                print(f"\n   âœ… GPU è®¡ç®—æµ‹è¯•æˆåŠŸ")
            except Exception as e:
                print(f"\n   âŒ GPU è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        else:
            print("   æœªæ£€æµ‹åˆ° GPU,ä½¿ç”¨ CPU æ¨¡å¼")
            
    except ImportError:
        print("âš ï¸  PyTorch æœªå®‰è£… (æœ¬é¡¹ç›®ä¸éœ€è¦)")
        return None
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ PyTorch æ—¶å‡ºé”™: {e}")
        return False
    
    return cuda_available


def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸ” GPU/CUDA/cuDNN ç¯å¢ƒéªŒè¯å·¥å…·\n")
    
    tf_has_gpu = verify_tensorflow_gpu()
    pt_has_gpu = verify_pytorch_gpu()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("éªŒè¯æ€»ç»“")
    print("=" * 60)
    
    if tf_has_gpu:
        print("âœ… TensorFlow GPU æ”¯æŒæ­£å¸¸")
    else:
        print("âš ï¸  TensorFlow æœªæ£€æµ‹åˆ° GPU (å°†ä½¿ç”¨ CPU)")
    
    if pt_has_gpu is not None:
        if pt_has_gpu:
            print("âœ… PyTorch GPU æ”¯æŒæ­£å¸¸")
        else:
            print("âš ï¸  PyTorch æœªæ£€æµ‹åˆ° GPU (å°†ä½¿ç”¨ CPU)")
    else:
        print("â„¹ï¸  PyTorch æœªå®‰è£…")
    
    print("\n" + "=" * 60)
    
    # è¿”å›çŠ¶æ€ç 
    if tf_has_gpu or pt_has_gpu:
        print("\nâœ… è‡³å°‘ä¸€ä¸ªæ¡†æ¶æ”¯æŒ GPU")
        return 0
    else:
        print("\nâš ï¸  æ‰€æœ‰æ¡†æ¶éƒ½ä½¿ç”¨ CPU æ¨¡å¼")
        return 1


if __name__ == "__main__":
    sys.exit(main())
