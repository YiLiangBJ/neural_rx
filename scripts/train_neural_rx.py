#!/usr/bin/python3

# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: LicenseRef-NvidiaProprietary
#
# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
# property and proprietary rights in and to this material, related
# documentation and any modifications thereto. Any use, reproduction,
# disclosure or distribution of this material and related documentation
# without an express license agreement from NVIDIA CORPORATION or
# its affiliates is strictly prohibited.

# training of the neural receiver for a given configuration file
# the training loop can be found in utils.training_loop

####################################################################
# Parse args
####################################################################

import argparse
from os.path import exists

parser = argparse.ArgumentParser()
# the config defines the sys parameters
parser.add_argument("-config_name", help="config filename", type=str)
# GPU to use
parser.add_argument("-gpu", 
                    help="GPU selection: specific GPU number (0,1,2...), 'all' for all GPUs, or 'cpu' for CPU only", 
                    type=str, 
                    default="0")
# Easier debugging with breakpoints when running the code eagerly
parser.add_argument("-debug", help="Enable debug mode (disables XLA, enables eager execution)", action="store_true", default=False)
# Disable XLA compilation (faster startup, slower training)
parser.add_argument("--no-xla", help="Disable XLA compilation (useful for debugging)", action="store_true", default=False)

# Parse all arguments
args = parser.parse_args()

####################################################################
# Imports and GPU configuration
####################################################################

# Avoid warnings from TensorFlow
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
tf.get_logger().setLevel('ERROR')

# Initialize project paths (must be done before other imports)
import sys
script_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(script_dir)
sys.path.insert(0, parent_dir)

from utils.project_paths import init_project_paths, get_weights_path, get_logs_path
init_project_paths()  # Switch to project root and create directories

# Configure GPU/CPU usage
gpus = tf.config.list_physical_devices('GPU')
gpu_strategy = None

if args.gpu.lower() == 'cpu':
    # Force CPU only
    tf.config.set_visible_devices([], 'GPU')
    print('ğŸ–¥ï¸  ä½¿ç”¨ CPU è®­ç»ƒ (æ‰€æœ‰ GPU å·²ç¦ç”¨)')
    print('   âš ï¸  è­¦å‘Š: CPU è®­ç»ƒä¼šéå¸¸æ…¢!')
    
elif args.gpu.lower() == 'all':
    # Use all available GPUs
    if len(gpus) == 0:
        print('âŒ æœªæ£€æµ‹åˆ° GPU,åˆ‡æ¢åˆ° CPU æ¨¡å¼')
        tf.config.set_visible_devices([], 'GPU')
    elif len(gpus) == 1:
        print(f'ğŸ“Š æ£€æµ‹åˆ° 1 ä¸ª GPU,è‡ªåŠ¨ä½¿ç”¨')
        tf.config.experimental.set_memory_growth(gpus[0], True)
    else:
        print(f'ğŸ“Š ä½¿ç”¨æ‰€æœ‰ {len(gpus)} ä¸ª GPU è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ')
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        # Create multi-GPU strategy
        gpu_strategy = tf.distribute.MirroredStrategy()
        print(f'   ç­–ç•¥: {gpu_strategy.__class__.__name__}')
        print(f'   GPU åˆ—è¡¨: {[gpu.name for gpu in gpus]}')
        
else:
    # Use specific GPU
    try:
        gpu_id = int(args.gpu)
        if gpu_id < 0 or gpu_id >= len(gpus):
            print(f'âŒ GPU {gpu_id} ä¸å­˜åœ¨! å¯ç”¨ GPU æ•°é‡: {len(gpus)}')
            print(f'   å¯ç”¨é€‰é¡¹: 0-{len(gpus)-1}, "all", æˆ– "cpu"')
            sys.exit(1)
        
        # Set only the specified GPU visible
        tf.config.set_visible_devices([gpus[gpu_id]], 'GPU')
        tf.config.experimental.set_memory_growth(gpus[gpu_id], True)
        print(f'ğŸ¯ ä½¿ç”¨ GPU {gpu_id}: {gpus[gpu_id].name}')
        print(f'   å·²å¯ç”¨å†…å­˜å¢é•¿æ¨¡å¼')
        
    except ValueError:
        print(f'âŒ æ— æ•ˆçš„ GPU å‚æ•°: {args.gpu}')
        print(f'   æœ‰æ•ˆé€‰é¡¹: 0-{len(gpus)-1}, "all", æˆ– "cpu"')
        sys.exit(1)

print()

from utils import E2E_Model, training_loop, Parameters, load_weights

##################################################################
# Training parameters
##################################################################

# all relevant parameters are defined in the config_file
config_name = args.config_name

# initialize system parameters
sys_parameters = Parameters(config_name,
                            system='nrx',
                            training=True)
label = f'{sys_parameters.label}'
filename = get_weights_path(label)
training_logdir = get_logs_path()
training_seed = 42

# Debug mode: disable XLA and enable eager execution
if args.debug:
    tf.config.run_functions_eagerly(True)
    training_logdir = get_logs_path("debug")
    # Override XLA setting in debug mode
    sys_parameters.xla = False
    print("ğŸ› è°ƒè¯•æ¨¡å¼å·²æ¿€æ´»:")
    print("   - Eager execution: å¯ç”¨ (å¯ä»¥è®¾ç½®æ–­ç‚¹)")
    print("   - XLA ç¼–è¯‘: ç¦ç”¨ (æ— ç¼–è¯‘ç­‰å¾…)")
    print("   - æ—¥å¿—ç›®å½•: logs/debug/")
    print("   âš ï¸  æ³¨æ„: è°ƒè¯•æ¨¡å¼ä¼šæ˜¾è‘—é™ä½è®­ç»ƒé€Ÿåº¦!")
    print()

# Optional: disable XLA without full debug mode
if args.no_xla:
    sys_parameters.xla = False
    print("âš¡ XLA ç¼–è¯‘å·²ç¦ç”¨")
    print("   âœ… ä¼˜ç‚¹: æ— ç¼–è¯‘ç­‰å¾…,å¿«é€Ÿå¯åŠ¨")
    print("   âš ï¸  ç¼ºç‚¹: è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢")
    print()

#################################################################
# Start training
#################################################################

print("\n" + "=" * 70)
print("ğŸš€ å¼€å§‹è®­ç»ƒ")
print("=" * 70)
print(f"ğŸ“‹ é…ç½®: {config_name}")
print(f"ğŸ·ï¸  æ ‡ç­¾: {label}")

# GPU info
if args.gpu.lower() == 'cpu':
    print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: CPU")
elif args.gpu.lower() == 'all':
    print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {len(gpus)} ä¸ª GPU (åˆ†å¸ƒå¼è®­ç»ƒ)")
    if gpu_strategy:
        print(f"   ç­–ç•¥: {gpu_strategy.__class__.__name__}")
else:
    print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: GPU {args.gpu}")

print(f"ğŸ’¾ æƒé‡è·¯å¾„: {filename}")
print(f"ğŸ“Š æ—¥å¿—è·¯å¾„: {training_logdir}")
print(f"ğŸŒ± éšæœºç§å­: {training_seed}")
print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {'å¯ç”¨' if args.debug else 'ç¦ç”¨'}")
if args.debug:
    print(f"   âš ï¸  è°ƒè¯•æ¨¡å¼ä¼šç¦ç”¨ XLA å¹¶å¯ç”¨ eager execution")
print("=" * 70)
print()

# Create model (with multi-GPU strategy if applicable)
if gpu_strategy:
    print("\nğŸ”§ åœ¨åˆ†å¸ƒå¼ç­–ç•¥ä¸­åˆ›å»ºæ¨¡å‹...")
    with gpu_strategy.scope():
        sys_training = E2E_Model(sys_parameters, training=True)
        sys_training(1, 1.)  # run once to init weights
    print("âœ… åˆ†å¸ƒå¼æ¨¡å‹åˆ›å»ºå®Œæˆ")
else:
    sys_training = E2E_Model(sys_parameters, training=True)
    sys_training(1, 1.)  # run once to init weights in TensorFlow

sys_training.summary()

# load weights if the exists already
if exists(filename):
    print("\nğŸ’¡ æ£€æµ‹åˆ°å·²æœ‰æƒé‡ - åŠ è½½ä¸­...")
    load_weights(sys_training, filename)
    print("âœ… æƒé‡åŠ è½½å®Œæˆ")
else:
    print("\nğŸ†• ä»å¤´å¼€å§‹è®­ç»ƒ (æœªæ‰¾åˆ°å·²æœ‰æƒé‡)")

print()
print("âš™ï¸  è®­ç»ƒå‚æ•°:")
print(f"   ğŸ“š Epochs: {sys_parameters.training_schedule['epochs']}")
print(f"   ğŸ“¦ Batch size: {sys_parameters.training_schedule['batch_size']}")
print(f"   ğŸ‘¥ ç”¨æˆ·æ•°èŒƒå›´: {sys_parameters.min_num_tx} - {sys_parameters.max_num_tx}")
print(f"   ğŸ“¡ MCS ç´¢å¼•: {sys_parameters.mcs_index}")
print(f"   ğŸ“ˆ è¯„ä¼° EbNo: {sys_parameters.eval_ebno_db_arr} dB")
print(f"   âš¡ XLA åŠ é€Ÿ: {sys_parameters.xla}")
print()

if hasattr(sys_parameters, 'mcs_training_snr_db_offset'):
    mcs_training_snr_db_offset = sys_parameters.mcs_training_snr_db_offset
else:
    mcs_training_snr_db_offset = None

if hasattr(sys_parameters, 'mcs_training_probs'):
    mcs_training_probs = sys_parameters.mcs_training_probs
else:
    mcs_training_probs = None

print("ğŸ¬ å¯åŠ¨è®­ç»ƒå¾ªç¯...")
print("=" * 70)
print()

# run the training / weights are automatically saved
# UEs' MCSs will be drawn randomly
training_loop(sys_training,
              label=label,
              filename=filename,
              training_logdir=training_logdir,
              training_seed=training_seed,
              training_schedule=sys_parameters.training_schedule,
              eval_ebno_db_arr=sys_parameters.eval_ebno_db_arr,
              min_num_tx=sys_parameters.min_num_tx,
              max_num_tx=sys_parameters.max_num_tx,
              sys_parameters=sys_parameters,
              mcs_arr_training_idx=list(range(len(sys_parameters.mcs_index))), # train with all supported MCSs
              mcs_training_snr_db_offset=mcs_training_snr_db_offset,
              mcs_training_probs=mcs_training_probs,
              xla=sys_parameters.xla)

print()
print("=" * 70)
print("âœ… è®­ç»ƒå®Œæˆ!")
print(f"ğŸ’¾ æœ€ç»ˆæƒé‡: {filename}")
print(f"ğŸ“Š TensorBoard: tensorboard --logdir {training_logdir}")
print("=" * 70)
